# Importing Clusters (Manual)

Importing of clusters such as GKE, AKS, EKS or DOKS

. Assumes you have an ACM Hub running on top of a OCP
. Create some Spoke clusters
. Download pull-secret.txt from console.redhat.com
. Add the pull-secret in open-cluster-management
. Update the MultiClusterHub with the pull-secret
. On the Hub, create a namespace to represent the Spoke cluster
. Label that namespace as a managedCluster
. Create a ManagedCluster 
. Create a KlusterletAddonConfig
. Export the klusterlet-crd.yaml
. Export the import.yaml
. On the Spoke, apply the klusterlet-crd.yaml
. On the Spoke, apply the import.yaml


#### Create Spoke Clusters

Digital Ocean Kubernetes Service (DOKS)

----
doctl kubernetes cluster create blr1-kubernetes --region blr1 --node-pool="name=worker-pool;count=2"
export KUBECONFIG=/Users/burr/devnation/doks-argocd/.kube/config-blr1
doctl k8s cluster kubeconfig show blr1-kubernetes >> $KUBECONFIG

doctl kubernetes cluster list
----

Google Kubernetes Engine (GKE)

----
export KUBECONFIG=/Users/burr/xKS/.kubeconfig/gke1

gcloud container clusters create gke1 --zone us-central1-c --project alohaburr
gcloud container clusters get-credentials gke1 --zone us-central1-c --project alohaburr

gcloud container clusters list --project alohaburr
----

#### Pull Secret

Download your pull secret
https://console.redhat.com/openshift/install/pull-secret

image::./images/acm-import-1.png[][Pull Secret]

Switch to the open-cluster-management namespace

----
kubectl config set-context --current --namespace=open-cluster-management
# or 
oc project open-cluster-management
----

Add the secret 

----
kubectl create secret generic mypullsecret -n open-cluster-management --from-file=.dockerconfigjson=$HOME/Downloads/pull-secret.txt --type=kubernetes.io/dockerconfigjson
----

Update the MCH

----
cat <<EOF | kubectl apply -f -
apiVersion: operator.open-cluster-management.io/v1
kind: MultiClusterHub
metadata:
  name: multiclusterhub
  namespace: open-cluster-management
spec:
  imagePullSecret: mypullsecret
EOF
----

#### Create the ManagedCluster for BLR1 (DOKS)

----
kubectl create namespace blr1
kubectl label namespace blr1 cluster.open-cluster-management.io/managedCluster=blr1
----

----
cat <<EOF | kubectl -n blr1 apply -f -
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  name: blr1
spec:
  hubAcceptsClient: true
EOF
----

You should see "Pending Import"

image::./images/acm-import-3.png[][Pending Import]

And watch your ManagedClusters

----
watch kubectl get managedcluster
NAME            HUB ACCEPTED   MANAGED CLUSTER URLS                    JOINED   AVAILABLE   AGE
blr1            true                                                                        42s
local-cluster   true           https://api.iowa.burr-on-gcp.com:6443   True     True        104m
----

Create the KlusterletAddonConfig

----
cat <<EOF | kubectl -n blr1 apply -f -
apiVersion: agent.open-cluster-management.io/v1
kind: KlusterletAddonConfig
metadata:
  name: blr1
  namespace: blr1
spec:
  clusterName: blr1
  clusterNamespace: blr1
  applicationManager:
    enabled: true
  certPolicyController:
    enabled: true
  clusterLabels:
    cloud: auto-detect
    vendor: auto-detect
  iamPolicyController:
    enabled: true
  policyController:
    enabled: true
  searchCollector:
    enabled: true
  version: 2.1.0
EOF
----

Extract the artifacts to be applied to the blr1 spoke cluster

----
kubectl get secret blr1-import -n blr1 -o jsonpath={.data.crds\\.yaml} | base64 --decode > $HOME/blr1-klusterlet-crd.yaml
----

----
kubectl get secret blr1-import -n blr1 -o jsonpath={.data.import\\.yaml} | base64 --decode > $HOME/blr1-import.yaml
----


#### Update the BLR1 (DOKS) Cluster

Apply the CRD

----
kubectl apply -f $HOME/blr1-klusterlet-crd.yaml
----

Apply the import of the agent

----
kubectl apply -f $HOME/blr1-import.yaml
----

watch kubectl get pods -n open-cluster-management-agent

----
watch kubectl get pods -n open-cluster-management-agent
NAME                                             READY   STATUS    RESTARTS       AGE
klusterlet-b48d64b8c-nzf46                       1/1     Running   0              2m17s
klusterlet-registration-agent-5c587fb9c7-v9g24   1/1     Running   0              111s
klusterlet-work-agent-8ddd945f8-zt44p            1/1     Running   1 (101s ago)   111s
----

Note: You might see a temporary ErrImagePull

watch kubectl get pods -n open-cluster-management-agent-addon

----
watch kubectl get pods -n open-cluster-management-agent-addon
NAME                                                         READY   STATUS    RESTARTS   AGE
klusterlet-addon-appmgr-db4c7f64-tg78v                       1/1     Running   0          88s
klusterlet-addon-certpolicyctrl-5b795667cc-fb9n8             1/1     Running   0          88s
klusterlet-addon-iampolicyctrl-7b9bb8fbb6-c5xck              1/1     Running   0          88s
klusterlet-addon-operator-8568585f58-dgz5j                   1/1     Running   0          106s
klusterlet-addon-policyctrl-config-policy-656fcdf4f4-ls89s   1/1     Running   0          88s
klusterlet-addon-policyctrl-framework-54df6968ff-sqn95       3/3     Running   0          88s
klusterlet-addon-search-d49bf798c-rcnbv                      1/1     Running   0          88s
klusterlet-addon-workmgr-6bf8bff9cb-nz75d                    1/1     Running   0          88s
----

image::./images/acm-import-4.png[][Ready]


#### Back on the Hub

----
kubectl get managedcluster
NAME            HUB ACCEPTED   MANAGED CLUSTER URLS                    JOINED   AVAILABLE   AGE
blr1            true                                                   True     True        12m
local-cluster   true           https://api.iowa.burr-on-gcp.com:6443   True     True        144m
----

Available True

At this point you can add labels to see Apps deploy

----
kubectl label managedcluster blr1 env=prod
----

#### On the BLR1 Spoke

----
kubectl get pods -n accounting
NAME                          READY   STATUS    RESTARTS   AGE
accounting-69bc96bcfd-l74f5   1/1     Running   0          69s
----

#### Create the ManagedCluster for GKE1

----
kubectl create namespace gke1
kubectl label namespace gke1 cluster.open-cluster-management.io/managedCluster=gke1
----

----
cat <<EOF | kubectl -n gke1 apply -f -
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  name: gke1
spec:
  hubAcceptsClient: true
EOF
----

You should see "Pending Import"

image::./images/acm-import-2.png[][Pending Import]

Check your ManagedClusters

----
kubectl get managedcluster
NAME            HUB ACCEPTED   MANAGED CLUSTER URLS                    JOINED   AVAILABLE   AGE
gke1            true                                                                        42s
local-cluster   true           https://api.iowa.burr-on-gcp.com:6443   True     True        104m
----

Create the KlusterletAddonConfig

----
cat <<EOF | kubectl -n gke1 apply -f -
apiVersion: agent.open-cluster-management.io/v1
kind: KlusterletAddonConfig
metadata:
  name: gke1
  namespace: gke1
spec:
  clusterName: gke1
  clusterNamespace: gke1
  applicationManager:
    enabled: true
  certPolicyController:
    enabled: true
  clusterLabels:
    cloud: auto-detect
    vendor: auto-detect
  iamPolicyController:
    enabled: true
  policyController:
    enabled: true
  searchCollector:
    enabled: true
  version: 2.1.0
EOF
----

Extract the artifacts to be applied to the gke1 spoke cluster

----
kubectl get secret gke1-import -n gke1 -o jsonpath={.data.crds\\.yaml} | base64 --decode > $HOME/gke1-klusterlet-crd.yaml
----

----
kubectl get secret gke1-import -n gke1 -o jsonpath={.data.import\\.yaml} | base64 --decode > $HOME/gke1-import.yaml
----

#### Update the GKE1 Cluster

Double check you are connected to the correct spoke cluster

----
gcloud container clusters list --project alohaburr
NAME  LOCATION       MASTER_VERSION   MASTER_IP     MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
gke1  us-central1-c  1.21.6-gke.1503  35.225.97.90  e2-medium     1.21.6-gke.1503  3          RUNNING
----

----
kubectl cluster-info
Kubernetes control plane is running at https://35.225.97.90
GLBCDefaultBackend is running at https://35.225.97.90/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy
KubeDNS is running at https://35.225.97.90/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://35.225.97.90/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy
----

Apply the CRD 

----
kubectl apply -f $HOME/gke1-klusterlet-crd.yaml
----

Apply the import for the agent to the 

----
kubectl apply -f $HOME/gke1-import.yaml
----

----
watch kubectl get pods -n open-cluster-management-agent
NAME                                            READY   STATUS    RESTARTS   AGE
klusterlet-b48d64b8c-phxv2                      1/1     Running   0          36s
klusterlet-registration-agent-66f65d568-mhfnc   1/1     Running   0          24s
klusterlet-work-agent-65f6477d7-pmhcp           1/1     Running   0          24s
----

----
watch kubectl get pods -n open-cluster-management-agent-addon
NAME                                                        READY   STATUS    RESTARTS   AGE
klusterlet-addon-appmgr-5bf88c5f4b-r8qms                    1/1     Running   0          41s
klusterlet-addon-certpolicyctrl-6c78f96d88-mwhgk            1/1     Running   0          40s
klusterlet-addon-iampolicyctrl-7774d5f858-4mmmx             1/1     Running   0          41s
klusterlet-addon-operator-8568585f58-r8sgg                  1/1     Running   0          73s
klusterlet-addon-policyctrl-config-policy-cfcbcd7fd-s2btc   1/1     Running   0          40s
klusterlet-addon-policyctrl-framework-d8998884-9lf2v        3/3     Running   0          40s
klusterlet-addon-search-755665bb5f-jlpj4                    1/1     Running   0          39s
klusterlet-addon-workmgr-5cf6cd4955-r579w                   1/1     Running   0          38s
----

image::./images/acm-import-5.png[][Ready]


#### Clean Up

Remove the labels to undeploy apps

----
kubectl label managedcluster blr1 env-
----

Destroy spoke clusters

----
gcloud container clusters delete gke1 --zone us-central1-c --project alohaburr
doctl k8s cluster delete blr1-kubernetes
----


Supporting Documentation Links

https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.1/html/manage_cluster/importing-a-target-managed-cluster-to-the-hub-cluster#importing-a-managed-cluster-with-the-cli

https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.1/html/manage_cluster/importing-a-target-managed-cluster-to-the-hub-cluster#importing-an-existing-cluster-with-the-console

https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.4/html/install/installing#advanced-config-hub


# Importing Clusters (Auto)

https://github.com/stolostron/cm-cli/releases

https://cloud.redhat.com/blog/bring-your-own-fleet-with-red-hat-advanced-cluster-management-for-kubernetes-auto-import-and-automation-tools

----
cm attach cluster blr1 --cluster-kubeconfig=/Users/burr/devnation/doks-argocd/.kube/config-blr1 --cluster-kubecontext=do-blr1-blr1-kubernetes
----

----
cm attach cluster gke1 --cluster-kubeconfig=/Users/burr/xKS/.kubeconfig/gke1-config --cluster-kubecontext=gke_ocp42project_europe-west3-a_gke1
----

----
cm attach cluster ams3 --cluster-kubeconfig=/Users/burr/devnation/doks-argocd/.kube/config-ams3 --cluster-kubecontext=do-ams3-ams3-kubernetes
----

----
cm attach cluster tor1 --cluster-kubeconfig=/Users/burr/devnation/doks-argocd/.kube/config-tor1 --cluster-kubecontext=do-tor1-tor1-kubernetes
----


#### Extras

----
kubectl label managedcluster ams3 cloud=Alibaba --overwrite
kubectl label managedcluster blr1 cloud=VMWare --overwrite
kubectl label managedcluster tor1 cloud=IBM --overwrite

kubectl label managedcluster lon1 cloud=VSphere
kubectl label managedcluster sgp1 cloud=IBM

kubectl label managedcluster burr cloud=Amazon
kubectl label managedcluster fred cloud=Azure
kubectl label managedcluster sammy cloud=vSphere
kubectl label managedcluster george cloud=IBM
kubectl label managedcluster mary cloud=Alibaba
kubectl label managedcluster sally cloud=Google
----

----
export KUBECONFIG=/Users/burr/devnation/doks-argocd/.kube/config-ams3
doctl kubernetes cluster create ams3-kubernetes --region ams3 --node-pool="name=worker-pool;count=3"

export KUBECONFIG=/Users/burr/devnation/doks-argocd/.kube/config-lon1
doctl kubernetes cluster create lon1-kubernetes --region lon1 --node-pool="name=worker-pool;count=3"

export KUBECONFIG=/Users/burr/devnation/doks-argocd/.kube/config-sgp1
doctl kubernetes cluster create sgp1-kubernetes --region sgp1 --node-pool="name=worker-pool;count=3"
----

----
cat <<EOF | kubectl apply -f -
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: ClusterClaim
metadata:
  name: version.openshift.io
spec:
  value: 4.10.0-sho
EOF
----

----
# not tested
export KUBECONFIG=/Users/burr/xKS/.kubeconfig/frankfurt

gcloud container clusters create frankfurt --zone europe-west3-a --node-pool default-pool --num-nodes 1
gcloud container clusters get-credentials frankfurt --zone europe-west3-a

gcloud container clusters list
----


Graviton
----
https://mirror.openshift.com/pub/openshift-v4/aarch64/clients/ocp/stable/openshift-install-mac-arm64.tar.gz

codesign --deep --force -s - /Users/burr/openshift/graviton-bin/openshift-install

----
